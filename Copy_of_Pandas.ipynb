{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOd/r4BhGlW4CO8pgVrxsK/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibinmbiju/Recap/blob/main/Copy_of_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following 2 files are LateX files"
      ],
      "metadata": {
        "id": "SInnbv8oe79M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a)**\n",
        "w.r.t w1"
      ],
      "metadata": {
        "id": "MqCe2DEQegjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\documentclass[12pt]{article}\n",
        "\\begin{document}\n",
        "function:\n",
        "\\[\n",
        "  f = \\mathrm{sum}((w1\\cdot \\mathrm{vector}(1)+w2\\cdot x-y)^{2})\n",
        "\\]\n",
        "\n",
        "gradient:\n",
        "\\[\n",
        "  \\frac{\\partial f}{\\partial w1} = 2\\cdot \\mathrm{sum}(w1\\cdot \\mathrm{vector}(1)+w2\\cdot x-y)\n",
        "\\]\n",
        "where\n",
        "\\begin{itemize}\n",
        "  \\item $w1$ is a scalar\n",
        "  \\item $w2$ is a scalar\n",
        "  \\item $x$ is a vector\n",
        "  \\item $y$ is a vector\n",
        "\\end{itemize}\n",
        "\\end{document}"
      ],
      "metadata": {
        "id": "kAAUV9a4d0wj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b)w.r.t w2"
      ],
      "metadata": {
        "id": "_LGupOqCe2Mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\documentclass[12pt]{article}\n",
        "\\begin{document}\n",
        "function:\n",
        "\\[\n",
        "  f = \\mathrm{sum}((w1\\cdot \\mathrm{vector}(1)+w2\\cdot x-y)^{2})\n",
        "\\]\n",
        "\n",
        "gradient:\n",
        "\\[\n",
        "  \\frac{\\partial f}{\\partial w2} = 2\\cdot (w1\\cdot \\mathrm{vector}(1)+w2\\cdot x-y)^\\top \\cdot x\n",
        "\\]\n",
        "where\n",
        "\\begin{itemize}\n",
        "  \\item $w1$ is a scalar\n",
        "  \\item $w2$ is a scalar\n",
        "  \\item $x$ is a vector\n",
        "  \\item $y$ is a vector\n",
        "\\end{itemize}\n",
        "\\end{document}"
      ],
      "metadata": {
        "id": "iIfCpq6seq22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 2**\n",
        "\n",
        "\n",
        "**a)**\n",
        "The purpose of Automatic Differentiation is to compute derivatives efficiently by operating directly on programs rather than mathematical expressions, leveraging intermediate variables and handling control flow.\n",
        "\n",
        "**Differences and issues resolved:**\n",
        "\n",
        "Numerical differentiation issues: Suffers from truncation/rounding errors and requires O(n) evaluations for n-dimensional gradients, making it inefficient for high-dimensional problems.\n",
        "Symbolic differentiation issues: Suffers from \"expression swell\" where derivatives become exponentially longer than original functions, and has difficulty handling control flow structures.\n",
        "Automatic Differentiation resolves these by providing exact computation (like symbolic) while avoiding expression swell and efficiently handling control flow.\n",
        "\n",
        "**b)**\n",
        "**Forward mode:** Computes one column of the Jacobian per pass. Efficient when there are few inputs and many outputs (n << m).\n",
        "Reverse mode: Computes one row of the Jacobian per pass. Efficient when there are many inputs and few outputs (particularly useful for neural networks with many parameters and scalar loss functions).\n",
        "\n",
        "**c)**\n",
        "Forward mode requires one pass per input dimension\n",
        "Reverse mode requires just one pass regardless of input dimensions\n",
        "For gradients of functions with many inputs and few outputs, reverse mode is more efficient\n",
        "d)\n",
        "In reverse mode Automatic Differentiation, memory consumption can become a bottleneck because the system needs to store all intermediate values from the forward pass to compute derivatives during the reverse pass.\n",
        "\n",
        "Checkpointing strategies helps by:\n",
        "\n",
        "Storing values only at selected checkpoints rather than all intermediate values\n",
        "Recomputing intermediate values as needed by running forward passes from checkpoints\n",
        "Trading increased computation time for reduced memory usage\n",
        "A practical example\n",
        "\n",
        "Checkpointing in recurrent neural networks reduced memory usage by 95% while only increasing computation time by 33%, enabling training of much larger models that would otherwise exceed GPU memory limits."
      ],
      "metadata": {
        "id": "FDWuAqTxdUoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pp0eZP0ngcN7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9a87a09-fa45-42be-b93b-10659cd074dd"
      },
      "source": [
        "## Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95f2afdb-3f1a-49a9-99cf-e459c70d69ba"
      },
      "source": [
        "#### a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c00844e-de42-4e9e-9a83-84c81c31b729"
      },
      "source": [
        "1. First, we need to calculate the Pearson correlation between user C and all other users. For this, we'll look at items rated by both users.  \n",
        "2. Calculating similarity between C and each user:\n",
        "\n",
        "\n",
        "> For C and A:  \n",
        "Common items: a, c, d, g, h  \n",
        "C: [2, 1, 3, 5, 3]  \n",
        "A: [4, -, 5, 3, 2]  \n",
        "This will give us a Pearson correlation value\n",
        "$$Σ((C-avgC)(A-avgA)) / sqrt(Σ(C-avgC)²×Σ(A-avgA)²)$$\n",
        "Average C = 2.8  \n",
        "Average A = 3.5\n",
        "$$Correlation(C,A) = -1.5/sqrt(8.8 × 5) = -1.5/sqrt(44) = -0.226$$\n",
        "\n",
        "> For C and B:  \n",
        "Common items: c, d, f, g  \n",
        "C: [1, 3, 4, 5]  \n",
        "B: [4, 3, 2, 1]  \n",
        "Average C = 3.25  \n",
        "Average B = 2.5\n",
        "$$Correlation(C,B) = -6.5/sqrt(8.75 × 5) = -6.5/sqrt(43.75) = -0.982$$\n",
        "\n",
        ">For C and D:  \n",
        "Common items: a, c, d, f, g, h  \n",
        "C: [2, 1, 3, 4, 5, 3]  \n",
        "D: [1, 1, -, -, 4, 2]  \n",
        "Average C = 3  \n",
        "Average D = 2\n",
        "$$Correlation(C,D) = 1/sqrt(2 × 0.6667) = 1/sqrt(1.3334) = 0.866$$\n",
        "\n",
        "rCe = (0.866 × 4 + (-0.226 × 1)) / (|0.866| + |-0.226|)\n",
        "= (3.464 - 0.226) / 1.092\n",
        "= 3.238 / 1.092\n",
        "= 2.966\n",
        "\n",
        "rCe ≈ 3.0 using User-User CF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58149b13-bb7a-4668-a95d-32914df640ae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Exercise 4**\n",
        "\n",
        "c)  We can improve performance by:\n",
        "\n",
        "*   Decreasing Learning Rate : Instead of using a constant alpha , we can decrease it linearly or exponentially\n",
        "\n",
        "\n",
        "`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BTmQM1g3RZIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 5**\n",
        "\n",
        "Part (a):\n",
        "\n",
        "\n",
        "\n",
        "*   **join()** : Joins two RDDs based on a common key.\n",
        "\n",
        "     Example: If RDD1 = [(1, \"Ibin\"), (2, \"Colin\")] and RDD2 = [(1, \"Alex\"), (2, \"Martin\")], the result of join() would be [(1, (\"Ibin\", \"Alex\")),   (2,   (\"Colin\", \"Martin\"))].\n",
        "*   **sortBy()** : Sorts an RDD by a given key or transformation.\n",
        "\n",
        "     Example: For an RDD of numbers like [4, 1, 3, 2], sortBy with identity function would return [1, 2, 3, 4].\n",
        "   \n",
        "\n",
        "*  **groupBy()** : Groups elements in an RDD by a specified function, returning a list of values for each key.\n",
        "\n",
        "     Example: Given an RDD of pairs [(1, \"a\"), (1, \"b\"), (2, \"c\")], groupBy on the first element would produce [(1, [\"a\", \"b\"]), (2, [\"c\"])].\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9kOgnKIaLttn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part(b)\n",
        "\n",
        "*   Transformations:\n",
        "\n",
        "                   union(otherDataset)\tReturn a new dataset that contains the union of the elements in the source dataset and the argument.\n",
        "                   distinct() – Remove duplicate elements.\n",
        "                   reduceByKey() – Aggregate values by key.\n",
        "\n",
        "\n",
        "\n",
        "*   Actions\n",
        "            take(n) – Retrieve the first n elements from the RDD.\n",
        "            first()\tReturn the first element of the dataset (similar to take(1)).\n",
        "            count() – Count the number of elements.\n",
        "            \n",
        "\n"
      ],
      "metadata": {
        "id": "YRC1rwbWNCF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RDDTransformations\").getOrCreate()\n",
        "\n",
        "# Define the schema for the data\n",
        "schema = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"age\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "# Create RDDs\n",
        "data1 = [(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 35)]\n",
        "data2 = [(\"David\", 40), (\"Eve\", 28), (\"Alice\", 25)]\n",
        "\n",
        "rdd1 = spark.sparkContext.parallelize(data1)\n",
        "rdd2 = spark.sparkContext.parallelize(data2)\n",
        "\n",
        "# Transformations\n",
        "# 1. Union\n",
        "rdd_union = rdd1.union(rdd2)\n",
        "\n",
        "# 2. Distinct\n",
        "rdd_distinct = rdd_union.distinct()\n",
        "\n",
        "# 3. Reduce by Key (Assuming key is the name)\n",
        "rdd_reduced = rdd_distinct.reduceByKey(lambda x, y: x)\n",
        "\n",
        "# Actions\n",
        "# 1. Take 3 elements\n",
        "print(\"First 3 elements:\")\n",
        "print(rdd_reduced.take(3))\n",
        "\n",
        "# 2. First element\n",
        "print(\"\\nFirst element:\")\n",
        "print(rdd_reduced.first())\n",
        "\n",
        "# 3. Count elements\n",
        "print(\"\\nCount of elements:\")\n",
        "print(rdd_reduced.count())\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb8yuA12XON0",
        "outputId": "866d72fe-0116-4993-fe0a-8655f28fa042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 3 elements:\n",
            "[('Bob', 30), ('Charlie', 35), ('David', 40)]\n",
            "\n",
            "First element:\n",
            "('Bob', 30)\n",
            "\n",
            "Count of elements:\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A0yqAmqZL2rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RDD_to_DataFrame\").getOrCreate()"
      ],
      "metadata": {
        "id": "2sjWglH8OJP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcwYCnNrSN26",
        "outputId": "d6754e6f-5470-4d5d-876e-3315276806ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 6**\n",
        "\n",
        "**a)**"
      ],
      "metadata": {
        "id": "hEkx97CzKeKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "adult = fetch_ucirepo(id=2)\n",
        "\n",
        "\n",
        "adult_df = spark.createDataFrame(adult.data.features)\n",
        "\n",
        "adult_df.head()\n",
        "\n",
        "# Choosing only required columns\n",
        "adult_df_cleaned=adult_df.select('education','education-num','marital-status','sex','capital-gain','capital-loss','hours-per-week','native-country')\n",
        "adult_df_cleaned.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFyVqZwJSKkg",
        "outputId": "1f40038a-57a4-4053-8145-3ae59034e858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+--------------------+------+------------+------------+--------------+--------------+\n",
            "|   education|education-num|      marital-status|   sex|capital-gain|capital-loss|hours-per-week|native-country|\n",
            "+------------+-------------+--------------------+------+------------+------------+--------------+--------------+\n",
            "|   Bachelors|           13|       Never-married|  Male|        2174|           0|            40| United-States|\n",
            "|   Bachelors|           13|  Married-civ-spouse|  Male|           0|           0|            13| United-States|\n",
            "|     HS-grad|            9|            Divorced|  Male|           0|           0|            40| United-States|\n",
            "|        11th|            7|  Married-civ-spouse|  Male|           0|           0|            40| United-States|\n",
            "|   Bachelors|           13|  Married-civ-spouse|Female|           0|           0|            40|          Cuba|\n",
            "|     Masters|           14|  Married-civ-spouse|Female|           0|           0|            40| United-States|\n",
            "|         9th|            5|Married-spouse-ab...|Female|           0|           0|            16|       Jamaica|\n",
            "|     HS-grad|            9|  Married-civ-spouse|  Male|           0|           0|            45| United-States|\n",
            "|     Masters|           14|       Never-married|Female|       14084|           0|            50| United-States|\n",
            "|   Bachelors|           13|  Married-civ-spouse|  Male|        5178|           0|            40| United-States|\n",
            "|Some-college|           10|  Married-civ-spouse|  Male|           0|           0|            80| United-States|\n",
            "|   Bachelors|           13|  Married-civ-spouse|  Male|           0|           0|            40|         India|\n",
            "|   Bachelors|           13|       Never-married|Female|           0|           0|            30| United-States|\n",
            "|  Assoc-acdm|           12|       Never-married|  Male|           0|           0|            50| United-States|\n",
            "|   Assoc-voc|           11|  Married-civ-spouse|  Male|           0|           0|            40|             ?|\n",
            "|     7th-8th|            4|  Married-civ-spouse|  Male|           0|           0|            45|        Mexico|\n",
            "|     HS-grad|            9|       Never-married|  Male|           0|           0|            35| United-States|\n",
            "|     HS-grad|            9|       Never-married|  Male|           0|           0|            40| United-States|\n",
            "|        11th|            7|  Married-civ-spouse|  Male|           0|           0|            50| United-States|\n",
            "|     Masters|           14|            Divorced|Female|           0|           0|            45| United-States|\n",
            "+------------+-------------+--------------------+------+------------+------------+--------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b)**"
      ],
      "metadata": {
        "id": "3tDSD9txKpBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, col, mean, desc, round,count, avg,max,min\n"
      ],
      "metadata": {
        "id": "jRAOvwqoYlZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = adult_df_cleaned.groupBy(\"marital-status\").agg(\n",
        "    round(count(when(col(\"sex\") == \"Male\", 1)) / count(\"*\"),2).alias(\"male_ratio\")\n",
        ")\n",
        "df_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY9QXYSsaEuL",
        "outputId": "3b661965-7339-4063-9d2a-372d66970b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+\n",
            "|      marital-status|male_ratio|\n",
            "+--------------------+----------+\n",
            "|           Separated|      0.39|\n",
            "|       Never-married|      0.55|\n",
            "|Married-spouse-ab...|      0.52|\n",
            "|            Divorced|       0.4|\n",
            "|             Widowed|      0.19|\n",
            "|   Married-AF-spouse|      0.32|\n",
            "|  Married-civ-spouse|      0.89|\n",
            "+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c)**"
      ],
      "metadata": {
        "id": "9_FjPo02Kseo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_average_income = adult_df_cleaned.filter((col(\"sex\") == \"Female\") & (col(\"capital-gain\") >=50000)).groupBy(\"native-country\").agg(\n",
        "    avg(\"hours-per-week\").alias(\"Average hours per week\")\n",
        ")\n",
        "df_result_average_income.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZytJTBfApuN",
        "outputId": "a112b10a-da29-42ad-bdc5-23ff10579de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------------------+\n",
            "|    native-country|Average hours per week|\n",
            "+------------------+----------------------+\n",
            "|            Canada|                  57.0|\n",
            "|     United-States|              40.96875|\n",
            "|Dominican-Republic|                  40.0|\n",
            "|                 ?|                  32.5|\n",
            "+------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d)**"
      ],
      "metadata": {
        "id": "2slUXWf-KvZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "education_dict = adult_df_cleaned.select(\"education-num\", \"education\").distinct().rdd.collectAsMap()\n",
        "\n",
        "# Define a function to compute the highest and lowest education levels for a given DataFrame\n",
        "def get_education_levels(df, group_name):\n",
        "\n",
        "    education_levels = df.agg(\n",
        "        max(col(\"education-num\")).alias(\"highest_education_num\"),\n",
        "        min(col(\"education-num\")).alias(\"lowest_education_num\")\n",
        "    ).collect()[0]\n",
        "\n",
        "    highest_education = education_dict[education_levels[\"highest_education_num\"]]\n",
        "    lowest_education = education_dict[education_levels[\"lowest_education_num\"]]\n",
        "\n",
        "    return {\n",
        "        \"Group\": group_name,\n",
        "        \"Highest Education\": highest_education,\n",
        "        \"Lowest Education\": lowest_education\n",
        "    }\n",
        "\n",
        "income_group_1 = adult_df_cleaned.filter(col('capital-gain') <= 50000)\n",
        "income_group_2 = adult_df_cleaned.filter(col('capital-gain') > 50000)\n",
        "\n",
        "result_group_1 = get_education_levels(income_group_1, \"Income <= 50000\")\n",
        "result_group_2 = get_education_levels(income_group_2, \"Income >  50000\")\n",
        "\n",
        "result_table = [result_group_1, result_group_2]\n",
        "\n",
        "result_df = spark.createDataFrame(result_table)\n",
        "result_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8AaUiZ3BsU6",
        "outputId": "6628b3b2-8e39-4f96-d718-e4374060b406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------------+----------------+\n",
            "|          Group|Highest Education|Lowest Education|\n",
            "+---------------+-----------------+----------------+\n",
            "|Income <= 50000|        Doctorate|       Preschool|\n",
            "|Income >  50000|        Doctorate|         5th-6th|\n",
            "+---------------+-----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kBF1XzFY_SvQ"
      }
    }
  ]
}